{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maryp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maryp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maryp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "spacy.load('en')\n",
    "nlp = English()\n",
    "import nlp\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from string import punctuation as PUNCTS\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "PUNCTS = set(punct for punct in string.punctuation)\n",
    "STOP_WORDS = set(stopwords.words(\"english\")) - {'who', 'whom', 'what', 'when', 'where', 'why', 'how'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid1  qid2                                          question1  \\\n",
       "0     1     2  What is the step by step guide to invest in sh...   \n",
       "1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2     5     6  How can I increase the speed of my internet co...   \n",
       "3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_dup.csv').drop(columns='id', axis=1)\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of classes pairs/not pairs is: 149263/255024\n",
      "An example of duplicated questions: \n",
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
      "AND \n",
      "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>How do I read and find my YouTube comments?</td>\n",
       "      <td>How can I see all my Youtube comments?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>What can make Physics easy to learn?</td>\n",
       "      <td>How can you make physics easy to learn?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>What was your first sexual experience like?</td>\n",
       "      <td>What was your first sexual experience?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid1  qid2                                          question1  \\\n",
       "5     11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "7     15    16                     How can I be a good geologist?   \n",
       "11    23    24        How do I read and find my YouTube comments?   \n",
       "12    25    26               What can make Physics easy to learn?   \n",
       "13    27    28        What was your first sexual experience like?   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "5   I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "7           What should I do to be a great geologist?             1  \n",
       "11             How can I see all my Youtube comments?             1  \n",
       "12            How can you make physics easy to learn?             1  \n",
       "13             What was your first sexual experience?             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df.is_duplicate==1]\n",
    "not_duplicates = df[df.is_duplicate == 0]\n",
    "print(f'The proportion of classes pairs/not pairs is: {len(duplicates)}/{len(not_duplicates)}')\n",
    "print(f'An example of duplicated questions: \\n{duplicates.question1[5]} \\nAND \\n{duplicates.question2[5]}')\n",
    "duplicates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>am</th>\n",
       "      <th>and</th>\n",
       "      <th>ascendant</th>\n",
       "      <th>astrology</th>\n",
       "      <th>cap</th>\n",
       "      <th>capricorn</th>\n",
       "      <th>does</th>\n",
       "      <th>in</th>\n",
       "      <th>me</th>\n",
       "      <th>moon</th>\n",
       "      <th>rising</th>\n",
       "      <th>say</th>\n",
       "      <th>sun</th>\n",
       "      <th>that</th>\n",
       "      <th>this</th>\n",
       "      <th>triple</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  am  and  ascendant  astrology  cap  capricorn  does  in  me  moon  \\\n",
       "0      1   1    1          0          1    2          1     1   0   1     1   \n",
       "1      1   0    1          1          0    0          2     1   1   1     1   \n",
       "\n",
       "   rising  say  sun  that  this  triple  what  \n",
       "0       1    1    1     1     0       0     1  \n",
       "1       0    1    1     0     1       1     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is an example, will be later removed\n",
    "count_vectorizer = CountVectorizer()\n",
    "print(duplicates.question1[5], duplicates.question2[5])\n",
    "# Create the Bag-of-Words Model\n",
    "bag_of_words = count_vectorizer.fit_transform([duplicates.question1[5], duplicates.question2[5]])\n",
    "\n",
    "# Show the Bag-of-Words Model as a pandas DataFrame\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'day day date date shotgun shotgun wolf wolf child child'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk cleaning: very slow!\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def clean_sentence_lemmatizer(sentence):\n",
    "    \"\"\"\n",
    "    Receives a raw sentence and clean it using the following steps:  # BETTER\n",
    "    1. Remove all non-words\n",
    "    2. Transform the review in lower case\n",
    "    3. Remove all stop words\n",
    "    4. Perform lemmatizer\n",
    "\n",
    "    Args:\n",
    "        sentence: the sentence that will be cleaned\n",
    "    Returns:\n",
    "        a clean sentence using the mentioned steps above.\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence = re.sub(\"[^A-Za-z]\", \" \", sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = word_tokenize(sentence)\n",
    "    sentence = [lemmatizer.lemmatize(word) for word in sentence if word not in STOP_WORDS]\n",
    "    sentence = \" \".join(sentence)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "clean_sentence_lemmatizer('day days date dates shotgun shotguns wolf wolves child children')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPACY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization, lemmatization, removing stop words (except question opening words like who, why, etc) and puctuation and lowering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what step step guide invest share market india</td>\n",
       "      <td>what step step guide invest share market</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what story kohinoor koh noor diamond</td>\n",
       "      <td>what would happen indian government stole kohi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how i increase speed internet connection using...</td>\n",
       "      <td>how internet speed increased hacking dns</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why i mentally lonely how i solve</td>\n",
       "      <td>find remainder when math]23^{24}[/math divided...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve water quikly sugar salt met...</td>\n",
       "      <td>which fish would survive salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid1  qid2                                          question1  \\\n",
       "0     1     2     what step step guide invest share market india   \n",
       "1     3     4               what story kohinoor koh noor diamond   \n",
       "2     5     6  how i increase speed internet connection using...   \n",
       "3     7     8                  why i mentally lonely how i solve   \n",
       "4     9    10  which one dissolve water quikly sugar salt met...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0           what step step guide invest share market             0  \n",
       "1  what would happen indian government stole kohi...             0  \n",
       "2           how internet speed increased hacking dns             0  \n",
       "3  find remainder when math]23^{24}[/math divided...             0  \n",
       "4                which fish would survive salt water             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st way to clean q = re.sub(\"[^A-Za-z]\", \" \", q)?\n",
    "nlp = English()\n",
    "\n",
    "clean_question = lambda sentence: ' '.join([word.lemma_.lower() for word in nlp(sentence) \n",
    "                                            if word.lemma_ not in STOP_WORDS if word.lemma_ not in PUNCTS])\n",
    "df_clean = df.copy()\n",
    "df_clean['question1'] = df.apply(lambda row: clean_question(row['question1']), axis=1)\n",
    "df_clean['question2'] = df.apply(lambda row: clean_question(row['question2']), axis=1)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resub = lambda q: re.sub(\"[^A-Za-z]\", \" \", q)\n",
    "df_clean['question1'] = df_clean.apply(lambda row: resub(row['question1']), axis=1)\n",
    "df_clean['question2'] = df_clean.apply(lambda row: resub(row['question2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('df_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astrology i capricorn sun cap moon cap rising what say\n"
     ]
    }
   ],
   "source": [
    "# 2nd way to clean\n",
    "# I didn't use it\n",
    "def tok_stop_lem_punct(q, tokenize=True, stopwordize=True, punctuanize=True, lemmatize=True, lowerize=True):\n",
    "    nlp = English()\n",
    "    if stopwordize:\n",
    "        q = ' '.join([words.text for words in nlp(q) if words.text not in STOP_WORDS])\n",
    "    if lemmatize:\n",
    "        q = ' '.join([words.lemma_ for words in nlp(q)])\n",
    "    if punctuanize:\n",
    "        q = re.sub(\"[^A-Za-z]\", \" \", q)\n",
    "        q = ' '.join([words.strip() for words in q.split() if words not in PUNCTS])\n",
    "    if lowerize:\n",
    "        q = ' '.join([words.lower() for words in q.split()])\n",
    "    if tokenize:\n",
    "        tokenizer = spacy.tokenizer.Tokenizer(nlp.vocab)\n",
    "        q = tokenizer(q)\n",
    "    return q\n",
    "\n",
    "print(tok_stop_lem_punct(duplicates.question1[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2 = df.copy()\n",
    "df_clean2['question1'] = df.apply(lambda row: tok_stop_lem_punct(row['question1']), axis=1)\n",
    "df_clean2['question2'] = df.apply(lambda row: tok_stop_lem_punct(row['question2']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramm_count_dict_clean, unigramm_count_dict_initial = {}, {}\n",
    "bigramm_count_dict_initial, bigramm_count_dict_clean = {}, {}\n",
    "number_of_words_inq_initial, number_of_words_inq_clean = [], []\n",
    "lengths_of_questions_initial, lengths_of_questions_clean = [], []\n",
    "\n",
    "\n",
    "def count_basic_stats(df):\n",
    "    unigramm_count_dict = {}\n",
    "    bigramm_count_dict = {} \n",
    "    number_of_words_inq = []\n",
    "    lengths_of_questions = []\n",
    "    \n",
    "    for q1, q2 in zip(df.question1, df.question2):\n",
    "        unigramms_q1 = [word.text for word in nlp(q1)]\n",
    "        unigramms_q2 = [word.text for word in nlp(q2)]\n",
    "        number_of_words_inq.append(len(unigramms_q1))\n",
    "        number_of_words_inq.append(len(unigramms_q2))\n",
    "        lengths_of_questions.append(len(q1))\n",
    "        lengths_of_questions.append(len(q2))\n",
    "\n",
    "        for unigramm in unigramms_q1 + unigramms_q2:\n",
    "            if unigramm in unigramm_count_dict:\n",
    "                unigramm_count_dict[unigramm] += 1\n",
    "            else:\n",
    "                unigramm_count_dict[unigramm] = 1\n",
    "\n",
    "        bigramms_q1 = [' '.join(q1.split()[i:i+2]) for i in range(len(q1.split())) if i < len(q1.split()) - 1]\n",
    "        bigramms_q2 = [' '.join(q2.split()[i:i+2]) for i in range(len(q2.split())) if i < len(q2.split()) - 1]\n",
    "\n",
    "        for bigramm in bigramms_q1 + bigramms_q2:\n",
    "            if bigramm in bigramm_count_dict:\n",
    "                bigramm_count_dict[bigramm] += 1\n",
    "            else:\n",
    "                bigramm_count_dict[bigramm] = 1\n",
    "    return unigramm_count_dict, bigramm_count_dict, number_of_words_inq, lengths_of_questions\n",
    "\n",
    "\n",
    "unigramm_count_dict_initial, bigramm_count_dict_initial, number_of_words_inq_initial, \\\n",
    "    lengths_of_questions_initial = count_basic_stats(df)\n",
    "\n",
    "unigramm_count_dict_clean, bigramm_count_dict_clean, number_of_words_inq_clean, \\\n",
    "    lengths_of_questions_clean = count_basic_stats(df_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF(term) = term_frequency / sum(all terms frequences)\n",
    "\n",
    "tf_dict_initial = {unigramm : unigramm_count_dict_initial[unigramm] / sum(unigramm_count_dict_initial.values()) \n",
    "                  for unigramm in unigramm_count_dict_initial}\n",
    "tf_dict_clean = {unigramm : unigramm_count_dict_clean[unigramm] / sum(unigramm_count_dict_clean.values())\n",
    "                for unigramm in unigramm_count_dict_clean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232531\n",
      "2.1073827743530273\n",
      "232531\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def word_usage_count(df, column1, column2, ignore_register = False):\n",
    "    \"\"\"\n",
    "    Receives a df with raw sentences and counts word usage\n",
    "    Requires collections.Counter  \n",
    "    Args:\n",
    "        df: dataframe with some questions\n",
    "        column1, column2: columns to unite and count word usage\n",
    "        ignore_register: boolean parameter to ignore register or not, defaults to False\n",
    "    Returns:\n",
    "        Counter object {word: number}.\n",
    "    \"\"\"\n",
    "    questions1 = set(df[column1])\n",
    "    questions2 = set(df[column2])\n",
    "    unique_question_union = questions1.union(questions2)\n",
    "    words_usage_count = Counter()\n",
    "    for q in unique_question_union:\n",
    "        for word in q.split():\n",
    "            if ignore_register:\n",
    "                words_usage_count[word.lower()]+= 1\n",
    "            else:\n",
    "                words_usage_count[word]+= 1\n",
    "    return words_usage_count\n",
    "\n",
    "def word_existence_in_corpus(df,column1, column2, ignore_register=False):\n",
    "    \"\"\"\n",
    "    Receives a df with raw sentences and counts word usage\n",
    "    Requires collections.Counter  \n",
    "    Args:\n",
    "        df: dataframe with some questions\n",
    "        column1, column2: columns to unite and get words\n",
    "        ignore_register: boolean parameter to ignore register or not, defaults to False\n",
    "    Returns:\n",
    "        set of words occured in corpus from df.\n",
    "    \"\"\"\n",
    "    return set(word_usage_count(df, column1, column2, ignore_register = ignore_register).elements())\n",
    "\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "total_word_dict = word_usage_count(df,'question1', 'question2',)\n",
    "t1 = time.time()\n",
    "print(len(total_word_dict))\n",
    "print(t1 - t0)\n",
    "print(len(word_existence_in_corpus(df,'question1', 'question2',)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing with vectorizer\n",
    "\n",
    "took processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>preprocessed_q1</th>\n",
       "      <th>preprocessed_q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>what step step guide invest share market india</td>\n",
       "      <td>what step step guide invest share market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>what story kohinoor koh-i-noor diamond</td>\n",
       "      <td>what would happen indian government stole kohi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>how increase speed internet connection using vpn</td>\n",
       "      <td>how internet speed increased hacking dns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>why mentally lonely how solve</td>\n",
       "      <td>find remainder when math 23^ 24 /math divided ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>fish would survive salt water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid1  qid2                                          question1  \\\n",
       "0     1     2  What is the step by step guide to invest in sh...   \n",
       "1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2     5     6  How can I increase the speed of my internet co...   \n",
       "3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                     preprocessed_q1  \\\n",
       "0     what step step guide invest share market india   \n",
       "1             what story kohinoor koh-i-noor diamond   \n",
       "2   how increase speed internet connection using vpn   \n",
       "3                      why mentally lonely how solve   \n",
       "4  one dissolve water quikly sugar salt methane c...   \n",
       "\n",
       "                                     preprocessed_q2  \n",
       "0           what step step guide invest share market  \n",
       "1  what would happen indian government stole kohi...  \n",
       "2           how internet speed increased hacking dns  \n",
       "3  find remainder when math 23^ 24 /math divided ...  \n",
       "4                      fish would survive salt water  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p = pd.read_csv('preprocess_all.csv')\n",
    "df_p = df_p.drop(columns=['id', 'Unnamed: 0'])\n",
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what step step guide invest share market india</td>\n",
       "      <td>what step step guide invest share market</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what story kohinoor koh noor diamond</td>\n",
       "      <td>what would happen indian government stole kohi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how i increase speed internet connection using...</td>\n",
       "      <td>how internet speed increased hacking dns</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why i mentally lonely how i solve</td>\n",
       "      <td>find remainder when math          math divided...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve water quikly sugar salt met...</td>\n",
       "      <td>which fish would survive salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid1  qid2                                          question1  \\\n",
       "0     1     2     what step step guide invest share market india   \n",
       "1     3     4               what story kohinoor koh noor diamond   \n",
       "2     5     6  how i increase speed internet connection using...   \n",
       "3     7     8                  why i mentally lonely how i solve   \n",
       "4     9    10  which one dissolve water quikly sugar salt met...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0           what step step guide invest share market             0  \n",
       "1  what would happen indian government stole kohi...             0  \n",
       "2           how internet speed increased hacking dns             0  \n",
       "3  find remainder when math          math divided...             0  \n",
       "4                which fish would survive salt water             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.read_csv('df_clean.csv')\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vectorization from full corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cleaned data shape (404266, 5)\n",
      "TfIdfVectorizer shape (523972, 79158)\n",
      "Count Vectorizer/bag of words shape (523972, 79158)\n"
     ]
    }
   ],
   "source": [
    "# my clean\n",
    "df_clean = pd.read_csv('df_clean.csv')\n",
    "df_clean = df_clean.dropna()\n",
    "print(f'Initial cleaned data shape {df_clean.shape}')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus_clean = set(df_clean.question2).union(set(df_clean.question1))\n",
    "vectorizer_clean = TfidfVectorizer()\n",
    "X_clean = vectorizer_clean.fit_transform(corpus_clean)\n",
    "print(f'TfIdfVectorizer shape {X_clean.shape}')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv_clean = CountVectorizer()\n",
    "X2_clean = cv_clean.fit_transform(corpus_clean)\n",
    "print(f'Count Vectorizer/bag of words shape {X2_clean.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial preprocessed data shape (404247, 7)\n",
      "TfIdfVectorizer shape (286176, 67398)\n",
      "Count Vectorizer/bag of words shape with max_features 1000 (286176, 1000)\n"
     ]
    }
   ],
   "source": [
    "# this is good df\n",
    "df_p = df_p.dropna()\n",
    "print(f'Initial preprocessed data shape {df_p.shape}')\n",
    "\n",
    "corpus_p = set(df_p.preprocessed_q1).union(set(df_p.preprocessed_q1))\n",
    "vectorizer_p = TfidfVectorizer()\n",
    "X_p = vectorizer_p.fit_transform(corpus_p)\n",
    "print(f'TfIdfVectorizer shape {X_p.shape}')\n",
    "\n",
    "cv_p = CountVectorizer(max_features=1000)\n",
    "X2_p = cv_p.fit_transform(corpus_p)\n",
    "print(f'Count Vectorizer/bag of words shape with max_features 1000 {X2_p.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform first 10000 rows with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nevermind))\n",
    "# t0 = time.time()\n",
    "# c_vectorized_q1 = cv_clean.transform(df_clean.head(10000).question1)\n",
    "# c_vectorized_q2 = cv_clean.transform(df_clean.head(10000).question2)\n",
    "# print(f'Count Vectorizer transformed first 10000 rows into sparse matrix of shape {df_p_vectorized_q1.shape}')\n",
    "# df_p_vectorized_cv_q1 = pd.DataFrame(df_p_vectorized_q1.toarray(), columns = cv_clean.get_feature_names())\n",
    "# df_p_vectorized_cv_q2 = pd.DataFrame(df_p_vectorized_q2.toarray(), columns = cv_clean.get_feature_names())\n",
    "# print(f'We can applyt todense() and take df from that, that will be again shape {df_p_vectorized_cv_q1.shape}')\n",
    "# print('First few rows from that df: \\n')\n",
    "# df_p_vectorized_cv_q1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer transformed first 10000 rows into sparse matrix of shape (10000, 1000)\n",
      "We can applyt todense() and take df from that, that will be again shape (10000, 1000)\n",
      "First few rows from that df: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>12th</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  10  100  1000  11  12  12th  13  15  16  ...  write  writing  written  \\\n",
       "0    0   0    0     0   0   0     0   0   0   0  ...      0        0        0   \n",
       "1    0   0    0     0   0   0     0   0   0   0  ...      0        0        0   \n",
       "\n",
       "   wrong  year  years  yes  yet  young  youtube  \n",
       "0      0     0      0    0    0      0        0  \n",
       "1      0     0      0    0    0      0        0  \n",
       "\n",
       "[2 rows x 1000 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try Count Vectorizer on first 10000 rows - transform q1 and q2 to vectors\n",
    "import time\n",
    "t0 = time.time()\n",
    "df_p_vectorized_q1 = cv_p.transform(df_p.head(10000).preprocessed_q1)\n",
    "df_p_vectorized_q2 = cv_p.transform(df_p.head(10000).preprocessed_q2)\n",
    "print(f'Count Vectorizer transformed first 10000 rows into sparse matrix of shape {df_p_vectorized_q1.shape}')\n",
    "df_p_vectorized_cv_q1 = pd.DataFrame(df_p_vectorized_q1.toarray(), columns = cv_p.get_feature_names())\n",
    "df_p_vectorized_cv_q2 = pd.DataFrame(df_p_vectorized_q2.toarray(), columns = cv_p.get_feature_names())\n",
    "print(f'We can applyt todense() and take df from that, that will be again shape {df_p_vectorized_cv_q1.shape}')\n",
    "print('First few rows from that df: \\n')\n",
    "df_p_vectorized_cv_q1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finding cosine distance between q1[i] from question1 and q2[i] from question2 \n",
    "diagonal of pairwise distances between to matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of distances between q1_i and q2_i has length 10000 - should be 10000\n",
      "First 10 questions have cosine distance: \n",
      "[0.10557280900008414, 0.7113248654051871, 0.2254033307585166, 1.0, 0.5000000000000001, 0.0, 1.0, 1.0, -2.220446049250313e-16, 0.6464466094067263]\n"
     ]
    }
   ],
   "source": [
    "# counting cosine similarity between first 10000 qs\n",
    "from sklearn.metrics.pairwise import cosine_similarity # aka 1 - cosine distance\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "def count_cosine_dist_between_two_dfs(sparse_m1, sparse_m2):\n",
    "    \"\"\"\n",
    "    Receives  sparces matrices and counts pairwise cosine distancer  \n",
    "    Args:\n",
    "        matrices\n",
    "        \n",
    "    Returns:\n",
    "        list of pairwise distances\n",
    "    \"\"\"\n",
    "    \n",
    "    return [1 - cosine_similarity(sparse_m1.todense()[i, :], sparse_m2.todense()[i, :])[0][0] \n",
    "            for i in range((min(sparse_m1.shape[0], sparse_m2.shape[0])))]\n",
    "\n",
    "distancesq1iq2i = count_cosine_dist_between_two_dfs(df_p_vectorized_q1, df_p_vectorized_q2)\n",
    "print(f'Array of distances between q1_i and q2_i has length {len(distancesq1iq2i)} - should be {len(df_p_vectorized_cv_q1)}')\n",
    "print(f'First 10 questions have cosine distance: \\n{distancesq1iq2i[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating DF with cosine distance and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4.621645e-01</td>\n",
       "      <td>0.371100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.305596e-01</td>\n",
       "      <td>0.483123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.835034e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.226497e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.113249e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           distance        target\n",
       "count  1.000000e+04  10000.000000\n",
       "mean   4.621645e-01      0.371100\n",
       "std    3.305596e-01      0.483123\n",
       "min   -2.220446e-16      0.000000\n",
       "25%    1.835034e-01      0.000000\n",
       "50%    4.226497e-01      0.000000\n",
       "75%    7.113249e-01      1.000000\n",
       "max    1.000000e+00      1.000000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#distance_target = pd.DataFrame([distancesq1iq2i, df_clean.is_duplicate[:10000].values], columns= ['dist', 'target'])\n",
    "distance_target = pd.DataFrame({'distance': distancesq1iq2i, 'target': df_clean.is_duplicate[:10000].values})\n",
    "distance_target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shapes (7500,) (2500,) (7500,)\n",
      "Distribution of classes in target: \n",
      "0    62.64\n",
      "1    37.36\n",
      "Name: target, dtype: float64, \n",
      "0    63.64\n",
      "1    36.36\n",
      "Name: target, dtype: float64\n",
      "Classification report after LR: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74      1591\n",
      "           1       0.52      0.39      0.45       909\n",
      "\n",
      "    accuracy                           0.65      2500\n",
      "   macro avg       0.61      0.59      0.59      2500\n",
      "weighted avg       0.63      0.65      0.63      2500\n",
      "\n",
      "Confusion matrix after LR: \n",
      "[[1258  333]\n",
      " [ 553  356]]\n",
      "Classification report after RF: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74      1591\n",
      "           1       0.50      0.35      0.41       909\n",
      "\n",
      "    accuracy                           0.64      2500\n",
      "   macro avg       0.59      0.57      0.57      2500\n",
      "weighted avg       0.62      0.64      0.62      2500\n",
      "\n",
      "Confusion matrix after RF: \n",
      "[[1268  323]\n",
      " [ 589  320]]\n"
     ]
    }
   ],
   "source": [
    "X = distance_target.distance\n",
    "y = distance_target.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print('data shapes', X_train.shape, X_test.shape, y_train.shape)\n",
    "print(f'Distribution of classes in target: \\n{y_train.value_counts()/len(y_train)*100}, \\n{y_test.value_counts()/len(y_test)*100}')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "y_pred = lr.predict(X_test.values.reshape(-1, 1))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(f'Classification report after LR: \\n{classification_report(y_test, y_pred)}')\n",
    "print(f'Confusion matrix after LR: \\n{confusion_matrix(y_test, y_pred)}')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "y_predrf = rf.predict(X_test.values.reshape(-1, 1))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(f'Classification report after RF: \\n{classification_report(y_test, y_predrf)}')\n",
    "print(f'Confusion matrix after RF: \\n{confusion_matrix(y_test, y_predrf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Let's try to add Levenstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lev_dist(a1, a2):\n",
    "    source=a1.split()\n",
    "    target=a2.split()\n",
    "    if source == target:\n",
    "        return 0\n",
    "\n",
    "\n",
    "    # Prepare a matrix\n",
    "    slen, tlen = len(source), len(target)\n",
    "    dist = [[0 for i in range(tlen+1)] for x in range(slen+1)]\n",
    "    for i in range(slen+1):\n",
    "        dist[i][0] = i\n",
    "    for j in range(tlen+1):\n",
    "        dist[0][j] = j\n",
    "\n",
    "    # Counting distance, here is my function\n",
    "    for i in range(slen):\n",
    "        for j in range(tlen):\n",
    "            cost = 0 if source[i] == target[j] else 1\n",
    "            dist[i+1][j+1] = min(\n",
    "                            dist[i][j+1] + 1,   # deletion\n",
    "                            dist[i+1][j] + 1,   # insertion\n",
    "                            dist[i][j] + cost   # substitution\n",
    "                        )\n",
    "    return (dist[-1][-1])/\\\n",
    "           ((len(source)+len(target))/2)\n",
    "\n",
    "\n",
    "\n",
    "#df = pd.read_csv('preprocess_all.csv').dropna()\n",
    "df['lev_dist'] = np.vectorize(lev_dist)(df['preprocessed_q1'], df['preprocessed_q2'])\n",
    "df.to_csv('preprocess_all_lev.csv')\n",
    "df['lev_pred']=0\n",
    "df['lev_pred']=df.lev_dist < 0.35\n",
    "df[\"lev_pred\"]=df[\"lev_pred\"].astype(int)\n",
    "df['lev_true']=df.lev_pred ==df.is_duplicate\n",
    "print(df['lev_true'].value_counts())\n",
    "\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our new data will have shape (10000, 1500)\n",
      "Reduction in pipeline with PCA and t-SNE took 398.54s\n"
     ]
    }
   ],
   "source": [
    "# transforming that 10000 rows\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "\n",
    "pca_tsne = Pipeline([\n",
    "    (\"tsvd\", TruncatedSVD(n_components=1500, random_state=42)),\n",
    "    (\"tsne\", TSNE(n_components=3, random_state=42)),\n",
    "])\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=1500, random_state=42)\n",
    "t0 = time.time()\n",
    "df_clean_vectorized_cv_q1_reduced = tsvd.fit_transform(df_clean_vectorized_cv_q1)\n",
    "df_clean_vectorized_cv_q2_reduced = tsvd.transform(df_clean_vectorized_cv_q2)\n",
    "t1 = time.time()\n",
    "print(f'Our new data will have shape {df_clean_vectorized_cv_q2_reduced.shape}')\n",
    "print(f\"Reduction in pipeline with PCA and t-SNE took {round(t1-t0, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what step step guide invest share market india</td>\n",
       "      <td>what step step guide invest share market</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what story kohinoor koh noor diamond</td>\n",
       "      <td>what would happen indian government stole kohi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how i increase speed internet connection using...</td>\n",
       "      <td>how internet speed increased hacking dns</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why i mentally lonely how i solve</td>\n",
       "      <td>find remainder when math          math divided...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve water quikly sugar salt met...</td>\n",
       "      <td>which fish would survive salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid1  qid2                                          question1  \\\n",
       "0     1     2     what step step guide invest share market india   \n",
       "1     3     4               what story kohinoor koh noor diamond   \n",
       "2     5     6  how i increase speed internet connection using...   \n",
       "3     7     8                  why i mentally lonely how i solve   \n",
       "4     9    10  which one dissolve water quikly sugar salt met...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0           what step step guide invest share market             0  \n",
       "1  what would happen indian government stole kohi...             0  \n",
       "2           how internet speed increased hacking dns             0  \n",
       "3  find remainder when math          math divided...             0  \n",
       "4                which fish would survive salt water             0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
